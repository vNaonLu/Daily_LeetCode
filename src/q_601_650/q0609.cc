#include <gtest/gtest.h>
#include <iostream>
#include <leetcode/anyorder.hpp>
#include <string>
#include <unordered_map>
#include <vector>

using namespace std;

/**
 * This file is generated by leetcode_add.py
 *
 * 609.
 *      Find Duplicate File in System
 *
 * ––––––––––––––––––––––––––––– Description –––––––––––––––––––––––––––––
 *
 *   Given a list ‘paths’ of directory info, including the directory path,
 *   and all the files with contents in this directory, return “all the
 *   duplicate files in the file system in terms of their paths” . You may
 *   return the answer in “any order”
 *   A group of duplicate files consists of at least two files that have
 *   the same
 *   A single directory info string in the input list has the following
 *       -  ‘'root/d1/d2/.../dm f1.txt(f1_content) f2.txt(f2_content) ...
 *   fn.txt(fn_content)'’
 *   It means there are ‘n’ files ‘(f1.txt, f2.txt ... fn.txt)’ with
 *   content ‘(f1_content, f2_content ... fn_content)’ respectively in the
 *   directory ' ‘root/d1/d2/.../dm'’ . Note that ‘n ≥ 1’ and ‘m ≥ 0’ . If
 *   ‘m = 0’ , it means the directory is just the root
 *   The output is a list of groups of duplicate file paths. For each
 *   group, it contains all the file paths of the files that have the same
 *   content. A file path is a string that has the following
 *       -  ‘'directory_path/file_name.txt'’
 *
 * ––––––––––––––––––––––––––––– Constraints –––––––––––––––––––––––––––––
 *
 *   • ‘1 ≤ paths.length ≤ 2 × 10⁴’
 *   • ‘1 ≤ paths[i].length ≤ 3000’
 *   • ‘1 ≤ sum(paths[i].length) ≤ 5 × 10⁵’
 *   • ‘paths[i]’ consist of English letters, digits, ‘'/'’ , ‘'.'’ , ‘'('’ ,
 * ‘')'’ , and ‘' '’ . • You may assume no files or directories share the same
 * name in the same directory. • You may assume each given directory info
 * represents a unique directory. A single blank space separates the directory
 * path and file info. • Imagine you are given a real file system, how will you
 * search files? DFS or BFS? • If the file content is very large (GB level), how
 * will you modify your solution? • If you can only read the file by 1kb each
 * time, how will you modify your solution? • What is the time complexity of
 * your modified solution? What is the most time-consuming part and
 * memory-consuming part of it? How to optimize? • How to make sure the
 * duplicated files you find are not false positive?
 *
 */

struct q609 : public ::testing::Test {
  // Leetcode answer here
  class Solution {
  private:
    template <char sth, typename Iterator>
    Iterator find(Iterator beg, Iterator end) {
      while (beg != end) {
        if (*beg == sth) {
          return beg;
        }
        ++beg;
      }
      return end;
    }

    template <char sth, typename Iterator>
    Iterator findNot(Iterator beg, Iterator end) {
      while (beg != end) {
        if (*beg != sth) {
          return beg;
        }
        ++beg;
      }
      return end;
    }

    template <typename Iterator>
    vector<pair<string, string>> splitFileContent(Iterator beg, Iterator end) {
      auto res = vector<pair<string, string>>();
      auto it  = beg;
      while (it != end) {
        /// trim the space character
        beg = it = findNot<' '>(it, end);

        /// get the file name
        it        = find<'('>(it, end);
        auto file = string(beg, it);

        /// get the content
        beg          = ++it;
        it           = find<')'>(it, end);
        auto content = string(beg, it);

        /// ++it since the character ')' is useless for us now
        ++it;

        /// use move function to avoid the copy constructor
        res.emplace_back(move(file), move(content));
      }
      return res;
    }

  public:
    vector<vector<string>> findDuplicate(vector<string> &paths) {
      auto memo = unordered_map<string, vector<string>>();
      auto res  = vector<vector<string>>();
      for (auto &s : paths) {
        auto it        = find<' '>(s.begin(), s.end());
        auto directory = string(s.begin(), it);

        for (auto [file, content] : splitFileContent(it, s.end())) {
          /// store the file_name into the hash map
          memo[content].emplace_back(directory + '/' + move(file));
        }
      }
      for (auto &[c, files] : memo) {
        if (files.size() > 1) {
          /// the
          res.emplace_back(move(files));
        }
      }
      return res;
    }
  };
  class Solution *solution;
};

TEST_F(q609, sample_input01) {
  solution                     = new Solution();
  vector<string>         paths = {"root/a 1.txt(abcd) 2.txt(efgh)",
                                  "root/c 3.txt(abcd)", "root/c/d 4.txt(efgh)",
                                  "root 4.txt(efgh)"};
  vector<vector<string>> exp   = {
        {"root/a/2.txt", "root/c/d/4.txt", "root/4.txt"},
        {"root/a/1.txt",   "root/c/3.txt"             }
  };
  // Try EXPECT_EQ_ANY_ORDER_RECURSIVE
  // if the element is also matched in any order.
  EXPECT_EQ_ANY_ORDER(solution->findDuplicate(paths), exp);
  delete solution;
}

TEST_F(q609, sample_input02) {
  solution                     = new Solution();
  vector<string>         paths = {"root/a 1.txt(abcd) 2.txt(efgh)",
                                  "root/c 3.txt(abcd)", "root/c/d 4.txt(efgh)"};
  vector<vector<string>> exp   = {
        {"root/a/2.txt", "root/c/d/4.txt"},
        {"root/a/1.txt",   "root/c/3.txt"}
  };
  // Try EXPECT_EQ_ANY_ORDER_RECURSIVE
  // if the element is also matched in any order.
  EXPECT_EQ_ANY_ORDER(solution->findDuplicate(paths), exp);
  delete solution;
}